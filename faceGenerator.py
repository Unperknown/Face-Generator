# -*- coding: utf-8 -*-
"""Face Generator(DCGAN).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mX5DLuK1aaiGlqp6Aj4kKaChR7H3DXyL
"""

import tensorflow as tf
import tensorflow.contrib.slim as slim

X = tf.placeholder(tf.float32, [None, 64,64,3])
Y = tf.placeholder(tf.float32, [None, 10])
Z = tf.placeholder(tf.float32, [None, 100])

def GENERATOR(Z):
    x = slim.fully_connected(Z, (8 * 8 * 16), activation_fn=None)
    x = tf.reshape(x, [-1, 8, 8, 16])
    for i in range(3):
        x = slim.conv2d(x, 16, 3, 1, activation_fn=tf.nn.elu)
        x = slim.conv2d(x, 16, 3, 1, activation_fn=tf.nn.elu)
        x = upscale(x, 2)
    x = slim.conv2d(x, 3, 3, 1, activation_fn=None)
    return x

def upscale(x, scale):
    _, h, w, _ = int_shape(x)
    return tf.image.resize_nearest_neighbor(x, (h*scale, w*scale))

def int_shape(tensor):
    shape = tensor.get_shape().as_list()
    return [num if num is not None else -1 for num in shape]

def norm_img(image):
    return image/127.5 - 1.

def denorm_img(norm):    
    return tf.clip_by_value(((norm + 1)*127.), 0, 255)

def sample_z(m, n):
    return np.random.uniform(-0.1, 0.1, size=[m, n])

def DISCRIMINATOR(X):
    with tf.variable_scope('D', reuse=tf.AUTO_REUSE) as vs:
        x = slim.conv2d(X, 16, 3, 1, activation_fn=tf.nn.elu)
        x = slim.conv2d(x, 16, 3, 1, activation_fn=tf.nn.elu)
        x = slim.conv2d(x, 16, 3, 1, activation_fn=tf.nn.elu) # 64 * 16
        x = slim.conv2d(x, 32, 3, 2, activation_fn=tf.nn.elu) 

        x = slim.conv2d(x, 32, 3, 1, activation_fn=tf.nn.elu)
        x = slim.conv2d(x, 32, 3, 1, activation_fn=tf.nn.elu) # 32 * 32
        x = slim.conv2d(x, 48, 3, 2, activation_fn=tf.nn.elu) 

        x = slim.conv2d(x, 48, 3, 1, activation_fn=tf.nn.elu)
        x = slim.conv2d(x, 48, 3, 1, activation_fn=tf.nn.elu) # 16 * 48

        x = tf.layers.flatten(x)
        z = slim.fully_connected(x, 100, activation_fn=None)
    return z

import keras
import tensorflow as tf
import numpy as np
import cv2
import os
import math

from keras.preprocessing.image import load_img, img_to_array
from google.colab import drive
from google.colab.patches import cv2_imshow

keras.backend.set_image_data_format('channels_last')
images = []

drive.mount('/content/gdrive', force_remount=True)

files = os.listdir('/content/gdrive/My Drive/DATA')

for i in files:
    image = load_img('/content/gdrive/My Drive/DATA/{}'.format(i), False, target_size=(64,64))
    image = img_to_array(image)
    image = norm_img(image)
    images.append(image)
    
print(np.array(images).shape)

G = GENERATOR(Z)

RD = DISCRIMINATOR(X)
GD = DISCRIMINATOR(G)


L_REAL = tf.reduce_mean(tf.abs(G - X))
L_GENE = tf.reduce_mean(tf.abs(G - X))

K = tf.placeholder(tf.float32)

D_LOSS = L_REAL - K*L_GENE
G_LOSS = tf.reduce_mean(tf.abs(G - X))

D_solver = (tf.train.AdamOptimizer(learning_rate=0.0025)
            .minimize(D_LOSS))
G_solver = (tf.train.AdamOptimizer(learning_rate=0.0025)
            .minimize(G_LOSS))

K_NOW = 0.001
lam = 1e-3

sess = tf.Session()
sess.run(tf.global_variables_initializer())

gamma = 0.7
for i in range(1, 10000001):
    NOISE = sample_z(16,100)
    BAT_IMAGE = images[0:16]
    _, L_REAL_NOW, _RD = sess.run([D_solver, L_REAL, RD], 
                  feed_dict={
                      X: BAT_IMAGE,
                      Z: NOISE,
                      K: K_NOW })
    _, L_GENE_NOW = sess.run([G_solver, L_GENE], 
                  feed_dict={
                      X: BAT_IMAGE,
                      Z: _RD})
    
    K_NOW = K_NOW + lam * (gamma*L_REAL_NOW - L_GENE_NOW)
    measure = L_GENE_NOW + np.abs(gamma*L_REAL_NOW - L_GENE_NOW)
    
    if i % 10 == 0:
      print('Iter-{}; Convergence measure: {:.4} D Loss: {:.4}'.format(i / 10, measure, L_REAL_NOW))

    if i % 50 == 0:
        made_image = sess.run(G, feed_dict={Z:sample_z(16,100)})
        np.random.shuffle(images)
        for j in made_image[:5]:
            cv2.imwrite('{}.jpg'.format(i), cv2.cvtColor((j + 1) * 120, cv2.COLOR_RGB2BGR))
            img = cv2.imread('{}.jpg'.format(i), cv2.IMREAD_UNCHANGED)
            cv2_imshow(img)